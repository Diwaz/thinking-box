import { ChatGoogleGenerativeAI } from "@langchain/google-genai";
import { tool } from "@langchain/core/tools";
import * as z from "zod";
import { StateGraph, START, END, Command } from "@langchain/langgraph";
import { MessagesZodMeta } from "@langchain/langgraph";
import { registry } from "@langchain/langgraph/zod";
import { type BaseMessage } from "@langchain/core/messages";
import { isAIMessage, ToolMessage } from "@langchain/core/messages";
import { SystemMessage } from "@langchain/core/messages";
import { HumanMessage } from "@langchain/core/messages";
import { SYSTEM_PROMPT } from "./prompt";
import {exec} from "child_process"
import { applyPatch, createPatch } from "diff";
import { Sandbox } from '@e2b/code-interpreter'
import express from 'express';
import cors from 'cors';
import { WebSocket, WebSocketServer } from "ws";
import { PrismaClient } from "./generated/prisma";
import { createServer } from "http";
import { runAgenticManager } from "./agenticManager";


const app = express();

const server = createServer(app);
const wss = new WebSocketServer({server})

app.use(express.json());
app.use(cors());


interface ProjectStore {
  messages:[],
  llmCalls:number
}

const prisma = new PrismaClient();

const MessageState = z.object({
  messages: z.array(z.custom<BaseMessage>()).register(registry, MessagesZodMeta),
  llmCalls: z.number().optional()
})


type State = z.infer<typeof MessageState>;
type UserStore = Record<string,State>
type GlobalStore = Record<string,UserStore>

const globalStore:GlobalStore = {}

// {
//   "user1": {
//     "project-x0x": {
//       messages : [
//         {
//           "ai msg":"file created"
//         },

//         {
//           "human msg":"do dis"
//         }
//       ]
//     }
//   }
// }

const llm = new ChatGoogleGenerativeAI({
  model: "gemini-2.5-flash-lite",
});


const sandbox = await Sandbox.create("zcxo3nr01udjamtzcdn4")
console.log("sandbox url",sandbox.sandboxId)
// const host = sandbox.getHost(5173)
// console.log(`https://${host}`)

const createfile = tool(
  async ({ filePath, content }) => {
    const file = Bun.file(filePath);
    console.log("paths to write",file)
    // await Bun.write(file, content);

//     await sandbox.files.write(
//   filePath,
//   content,
// )
    return `File created successfully at ${filePath}`
  }, {
  name: "creates_new_file",
  description: "Creates new file and adds content to it",
  schema: z.object({
    filePath: z.string().describe("File path of the origin of the file"),
    content: z.string().describe("content or code to put inside file")
  })
})

const runShellCommands = tool (
  async ({ command }) => {
    console.log("cmd:",command);
//     await sandbox.commands.run(
//   `${command}`, {
//   onStdout: (data) => {
//     console.log("command output e2b:",data)
//   },
//   onStderr: (data) => {
//     console.log("command error e2b:",data)
//   },
// }
//     );


//     exec(`${command}`, (error, stdout, stderr) => {
//     if (error) {
//         console.log(`error: ${error.message}`);
//         return;
//     }
//     if (stderr) {
//         console.log(`stderr: ${stderr}`);
//         return;
//     }
//     console.log(`stdout: ${stdout}`);
// });

    return ` command executed in the terminal successfully `;
  },{
    name : "run_shell_command",
    description:"runs the shell command given by AI in the terminal",
    schema: z.object ({
      command: z.string().describe("shell command to run in bash terminal")
    })
  }
)
// const applyPatchTool = tool (
//   async ({file_to_edit,new_file})=>{
//     console.log("applying patch")
//     // apply patch logic 
//     console.log("file path of the old file",file_to_edit)
//     const oldFile = Bun.file(file_to_edit)
//     const oldFilesContents = await oldFile.text();
//     const patch = createPatch(file_to_edit,oldFilesContents,new_file)
//     const patchedFile = applyPatch(oldFilesContents,patch)
//     console.log("after applying patch",patchedFile)
//     await sandbox.files.write(
//   file_to_edit,
//   patchedFile,
// )
//     // await Bun.write(file_to_edit,patchedFile)
//   },
// {
//   name: "apply_patch_tool",
//   description: "takes the file path of the old file to edit and new content to apply patch and updates the old file with updated content",
//   schema: z.object({
//     file_to_edit: z.string().describe("file path of the old file to edit new update generated by AI"),
//     new_file: z.string().describe("new updated latest file given by the AI"),
//   })
// }
// )


const toolsByName = {
  [createfile.name]: createfile,
  [runShellCommands.name]: runShellCommands,
  // [applyPatchTool.name]:applyPatchTool
};

const tools = Object.values(toolsByName);
const llmWithTools = llm.bindTools(tools);



async function llmCall(state: State) {

  // if (state.llmCalls == 0){
    console.log("1st LLM CALLLLLLLL")
  const llmResponse = await llmWithTools.invoke([
    new SystemMessage(SYSTEM_PROMPT),
    ...state.messages
  ])

  const newCallCount = state.llmCalls + 1
  console.log("state of llmCalls",state.llmCalls)
  return {
    messages: [...state.messages, llmResponse],
    llmCalls: newCallCount,
  }


}

async function toolNode(state: State) {
  const lastMessage = state.messages.at(-1);

  if (lastMessage == null || !isAIMessage(lastMessage)) {
    return {
      messages: [],
    }
  }

  const result: ToolMessage[] = [];
  for (const toolCall of lastMessage.tool_calls ?? []) {
    const tool = toolsByName[toolCall.name];
    if (!tool) continue;
    const observation = await tool.invoke(toolCall);
    result.push(
      new ToolMessage({
        tool_call_id: toolCall.id,
        content:observation
      })
    );

  }

  return {
    messages: result
  }

}
async function shouldContinue(state: State) {
  const lastMessage = state.messages.at(-1);
  if (lastMessage == null || !isAIMessage(lastMessage)) {
    return END
  }

  if (lastMessage.tool_calls?.length) {
    return "toolNode";
  }
  return END;
}

const agent = new StateGraph(MessageState)
  .addNode("llmCall", llmCall)
  .addNode("toolNode", toolNode)
  .addEdge(START, "llmCall")
  .addConditionalEdges("llmCall", shouldContinue, ["toolNode", END])
  .addEdge("toolNode", "llmCall")
  .compile();

// const start_agent = async () => {
//   let state:State = {
//     messages: [],
//     llmCalls:0,
//   }
//   while (true) {
//     let inputFromUser = prompt("[You]:")

//     if (inputFromUser?.toLowerCase() === "quit"){
//       break;
//     }
//     if (!inputFromUser?.trim()){
//       continue
//     }
//     state.messages.push(new HumanMessage(inputFromUser))
//     const result = await agent.invoke(state)
//     state = result

//     for (const messages of state.messages) {
//       console.log(`[${messages._getType()}]:${messages.content}`);

//     }




//   }



// }
// start_agent();



app.post('/project',async(req,res)=>{
  const {userId,projectId,initialPrompt}= req.body;
  try{

    const response =  await prisma.project.create({
      data:{
        id:projectId,
        initialPrompt,
        userId, 
      }
    })
    console.log("/project response",response)

  return res.status(200).json({
    "msg":response
  });
  }catch(err){
    return res.status(400).json(err)
  }

})

app.get("/project/:id",async(req,res)=>{
  const {id} = await req.params;
  try {
    const projectData = await prisma.project.findFirst({
      where: {
        id
      },
      select:{
        id:true,
        title:true,
        initialPrompt:true,
        userId:true,
        conversationHistory:true
      }
    })
    res.status(200).json(projectData);
  }catch(err){
    console.log("err",err)
    res.status(404).json({
      "not found":err
    })
  }
})
const state:State ={
  messages:[],
  llmCalls:0,
}
app.post("/prompt",async (req,res)=>{
  const {prompt,projectId,userId} = req.body;

  if (!projectId || !prompt || !userId){
    return res.status(400).json({
      "msg":"invalid input"
    })
  }

  console.log("reached here w/ prompt",prompt)
      // const prompt = await projectData.initialPropmt

  if(!globalStore.userId){
    globalStore.userId={
      projectId :{
        messages:[],
        llmCalls:0
      }
    }
  }

  const projectState:State = globalStore.userId.projectId!

  projectState.messages.push(new HumanMessage(prompt))
  runAgenticManager(userId,projectId,projectState,clients)
  // const result = await agent.invoke(projectState)


  res.status(200).json({
  //  url:host,
    // messages:result.messages,
    status:"processing"
  })

})
const clients = new Map();

wss.on("connection", (ws, req) => {
  const params = new URLSearchParams(req.url.replace("/?", ""));
  const userId = params.get("userId");
  console.log("New WebSocket:", userId);

  if (userId) clients.set(userId, ws);

  ws.on("close", () => {
    clients.delete(userId);
    console.log("client disconnected")
  });
});

server.listen(8080,()=>{
  console.log("server started to listen")
});
